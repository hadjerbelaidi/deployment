import tensorflow as tf
import numpy as np
import joblib
import os
import logging

logger = logging.getLogger(__name__)

class CICIDSPredictor:
    def __init__(self):
        self.model = None
        self.scaler = None
        self.base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

    def _load_resources(self):
        """Charge le modÃ¨le uniquement s'il n'est pas dÃ©jÃ  en mÃ©moire"""
        if self.model is None:
            print("ğŸš€ Chargement des ressources ML en mÃ©moire...")
            model_path = os.path.join(self.base_path, 'models', 'mlp_model_subset.h5')
            scaler_path = os.path.join(self.base_path, 'models', 'scaler.pkl')
            
            # Charger le modÃ¨le avec des options d'Ã©conomie de mÃ©moire
            self.model = tf.keras.models.load_model(model_path, compile=False)
            self.scaler = joblib.load(scaler_path)
            print("âœ… Ressources ML chargÃ©es !")
            
    def predict(self, data):
        # --- CETTE PARTIE DOIT ÃŠTRE INDENTÃ‰E ---
        self._load_resources()
        
        # 1. Normalisation
        data_scaled = self.scaler.transform(data)
        
        # 2. PrÃ©diction (ProbabilitÃ©s brutes)
        predictions = self.model.predict(data_scaled, verbose=0)
        
        # --- LOGS DE DEBUG (Visibles dans Render) ---
        # On affiche les probabilitÃ©s pour chaque ligne du CSV
        probs = predictions.flatten().tolist()
        print(f"DEBUG - ProbabilitÃ©s brutes dÃ©tectÃ©es : {probs}")
        
        # 3. Seuil de dÃ©cision (AjustÃ© Ã  0.7 pour plus de prÃ©cision)
        # Retourne 1 (Attack) si probabilitÃ© > 0.7, sinon 0 (Normal)
        return (predictions > 0.7).astype(int).flatten().tolist()
