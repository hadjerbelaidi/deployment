import tensorflow as tf
import numpy as np
import joblib
import os
import logging

logger = logging.getLogger(__name__)

class CICIDSPredictor:
    def __init__(self):
        self.model = None
        self.scaler = None
        self.base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

    def _load_resources(self):
        """Charge le mod√®le uniquement s'il n'est pas d√©j√† en m√©moire"""
        if self.model is None:
            print("üöÄ Chargement des ressources ML en m√©moire...")
            model_path = os.path.join(self.base_path, 'models', 'mlp_model_subset.h5')
            scaler_path = os.path.join(self.base_path, 'models', 'scaler.pkl')
            
            # Charger le mod√®le avec des options d'√©conomie de m√©moire
            self.model = tf.keras.models.load_model(model_path, compile=False)
            self.scaler = joblib.load(scaler_path)
            print("‚úÖ Ressources ML charg√©es !")
            
    def predict(self, data):
        self._load_resources()
        
        # V√©rification intelligente : 
        # Si la valeur maximale est tr√®s petite (ex < 10), 
        # c'est que les donn√©es sont d√©j√† scal√©es.
        if data.values.max() < 10:
            print("INFO: Donn√©es d√©j√† scal√©es d√©tect√©es. Saut du transform.")
            data_final = data.values
        else:
            print("INFO: Donn√©es brutes d√©tect√©es. Application du Scaler.")
            data_final = self.scaler.transform(data)
        
        # Pr√©diction
        predictions = self.model.predict(data_final, verbose=0)
        
        probs = predictions.flatten().tolist()
        print(f"DEBUG - Probabilit√©s brutes d√©tect√©es : {probs}")
        
        # On remet le seuil √† 0.5 pour voir si √ßa bouge
        return (predictions > 0.5).astype(int).flatten().tolist()
