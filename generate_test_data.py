"""
Script pour gÃ©nÃ©rer des donnÃ©es de test CSV pour le systÃ¨me
ExÃ©cuter: python generate_test_data.py
"""

import numpy as np
import pandas as pd
import pickle

print("ğŸ”§ GÃ©nÃ©ration de donnÃ©es de test pour CICIDS2017\n")

# Charger le scaler pour connaÃ®tre les features
try:
    with open('models/scaler.pkl', 'rb') as f:
        scaler = pickle.load(f)
    
    n_features = scaler.n_features_in_
    print(f"âœ… Nombre de features: {n_features}")
    
except FileNotFoundError:
    print("âŒ Fichier scaler.pkl non trouvÃ© dans models/")
    print("Utilisation de 78 features par dÃ©faut")
    n_features = 78

# GÃ©nÃ©rer des donnÃ©es de test
print(f"\nğŸ“Š GÃ©nÃ©ration de 100 connexions de test...\n")

# CrÃ©er des noms de colonnes gÃ©nÃ©riques
feature_names = [f'feature_{i}' for i in range(n_features)]

# GÃ©nÃ©rer 50 connexions "normales" et 50 "attaques"
np.random.seed(42)

# Connexions normales (valeurs plus basses)
normal_data = np.random.rand(50, n_features) * 50

# Connexions attaques (valeurs plus Ã©levÃ©es et variables)
attack_data = np.random.rand(50, n_features) * 150 + 50

# Combiner les donnÃ©es
all_data = np.vstack([normal_data, attack_data])

# CrÃ©er les labels (0 = normal, 1 = attaque)
labels = np.array([0] * 50 + [1] * 50)

# MÃ©langer les donnÃ©es
indices = np.random.permutation(100)
all_data = all_data[indices]
labels = labels[indices]

# CrÃ©er le DataFrame
df = pd.DataFrame(all_data, columns=feature_names)
df['Label'] = labels

# Sauvegarder les fichiers de test

# 1. Fichier complet avec labels (pour tester l'accuracy)
df.to_csv('test_data_with_labels.csv', index=False)
print(f"âœ… CrÃ©Ã©: test_data_with_labels.csv")
print(f"   - {len(df)} lignes")
print(f"   - {len(df.columns)} colonnes (incluant Label)")
print(f"   - Attaques: {labels.sum()} ({labels.sum()/len(labels)*100:.1f}%)")
print(f"   - Normales: {len(labels) - labels.sum()} ({(len(labels) - labels.sum())/len(labels)*100:.1f}%)")

# 2. Fichier sans labels (pour prÃ©diction pure)
df_no_labels = df.drop('Label', axis=1)
df_no_labels.to_csv('test_data_no_labels.csv', index=False)
print(f"\nâœ… CrÃ©Ã©: test_data_no_labels.csv")
print(f"   - {len(df_no_labels)} lignes")
print(f"   - {len(df_no_labels.columns)} colonnes (sans Label)")

# 3. Petit Ã©chantillon (10 lignes) pour tests rapides
df_sample = df.head(10)
df_sample.to_csv('test_data_sample.csv', index=False)
print(f"\nâœ… CrÃ©Ã©: test_data_sample.csv")
print(f"   - {len(df_sample)} lignes")
print(f"   - Parfait pour tests rapides")

# 4. Fichier JSON pour test API unique
import json

single_test = {
    "features": all_data[0].tolist()
}

with open('test_single_prediction.json', 'w') as f:
    json.dump(single_test, f, indent=2)

print(f"\nâœ… CrÃ©Ã©: test_single_prediction.json")
print(f"   - 1 connexion pour test API")
print(f"   - Label rÃ©el: {'ATTAQUE' if labels[indices[0]] == 1 else 'NORMAL'}")

# Afficher un aperÃ§u
print("\n" + "="*60)
print("ğŸ“‹ AperÃ§u des premiÃ¨res lignes:")
print("="*60)
print(df.head())

print("\n" + "="*60)
print("âœ… Fichiers de test gÃ©nÃ©rÃ©s avec succÃ¨s !")
print("="*60)
print("\nğŸ“ Utilisation:")
print("   1. test_data_with_labels.csv â†’ Upload dans l'interface web")
print("   2. test_data_no_labels.csv â†’ Test sans connaÃ®tre les vraies rÃ©ponses")
print("   3. test_data_sample.csv â†’ Tests rapides (10 lignes)")
print("   4. test_single_prediction.json â†’ Test de l'API /predict")

print("\nğŸ§ª Pour tester localement:")
print("   python -c \"import pandas as pd; print(pd.read_csv('test_data_sample.csv'))\"")

print("\nğŸŒ Pour tester l'API (aprÃ¨s dÃ©ploiement):")
print("   curl -X POST https://TON_URL.onrender.com/api/predict_batch \\")
print("     -F 'file=@test_data_sample.csv'")

print("\n" + "="*60 + "\n")